{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makemore: part 4 (backprop ninja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3  # context length: how many characters do we take to predict the next one\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + \".\":\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]  # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(len(words) * 0.8)\n",
    "n2 = int(len(words) * 0.9)\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])  # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])  # 10%\n",
    "Xte, Yte = build_dataset(words[n2:])  # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok biolerplate done, now we get to the action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt: torch.Tensor, t: torch.Tensor):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f\"{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1: torch.Tensor= torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3661, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb]  # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1)  # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1  # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1 / n * hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1 / (n - 1) * (bndiff2).sum(0, keepdim=True)  # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact)  # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2  # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes  # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1  # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [\n",
    "    logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "    norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "    bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "    embcat, emb\n",
    "]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "Backprop through the whole thing manually, backpropagating through exactly all of the variables as they are defined in the forward pass above, one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `loss = -logprobs[range(n), Yb].mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-4.0038, -3.1041, -3.7185, -3.1968, -4.2434, -3.4439, -3.2138, -4.0724,\n",
       "        -3.1567, -4.3095, -3.0613, -1.6669, -2.8714, -3.0527, -2.9195, -3.2029,\n",
       "        -3.8922, -3.0940, -3.6493, -3.4853, -2.8710, -3.0203, -4.3420, -3.9962,\n",
       "        -3.5196, -2.8448, -3.0919, -3.8119, -2.7812, -3.5627, -3.3590, -3.1555],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(logprobs.shape)\n",
    "logprobs[range(n), Yb]  # plucking out the values from each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in simpler terms: loss = - (a + b + c + ...) / n\n",
    "# <==>\n",
    "# dloss/da = -1/n \n",
    "# dloss/db = -1/n\n",
    "# ...\n",
    "# And the rest of the elements in logprobs don't participate, their gradients are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==> dloss/dlogprobs:\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `logprobs = probs.log()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dloss/dprobs = dloss/dlogprobs * dlogprobs/dprobs\n",
    "dprobs = dlogprobs * (1.0 / probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `probs = counts * counts_sum_inv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful!! Shapes are not equal ([32, 27] vs [32, 1]) so broadcasting happens here. What broadcasting looks like:\n",
    "# c = a[3x3] * b[3x1]\n",
    "# a11*b1 + a12*b1 + a13*b1\n",
    "# a21*b2 + a22*b2 + a23*b2\n",
    "# a31*b3 + a32*b3 + a33*b3\n",
    "# c[3x3]\n",
    "dcounts_sum_inv = (dprobs * counts).sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `counts_sum_inv = counts_sum**-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum = dcounts_sum_inv * -1 * (counts_sum**-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `probs = counts * counts_sum_inv`\n",
    "##### `counts_sum = counts.sum(1, keepdims=True)`\n",
    "##### `counts = norm_logits.exp()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts = dprobs * counts_sum_inv \n",
    "\n",
    "# .sum is like\n",
    "# a11 + a12 + a13  <==> 1 + 0 + 0\n",
    "# a21 + a22 + a23  <==> 1 + 0 + 0\n",
    "# ...\n",
    "dcounts += dcounts_sum * 1.0 # or torch.ones_like(counts)\n",
    "\n",
    "\n",
    "# counts = norm_logits.exp()\n",
    "dnorm_logits = counts * dcounts  # norm_logits.exp() * dcounts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `norm_logits = logits - logit_maxes`\n",
    "##### `logit_maxes = logits.max(1, keepdim=True).values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits.max(1, keepdim=True).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  2, 19, 15, 15, 25, 16,  3, 19,  8, 15,  3, 22, 18, 19,  5,  2,  1,\n",
       "        22, 19, 15, 19, 22, 22, 23,  5, 22, 20, 24,  6, 24, 13])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_logits = logits - logit_maxes\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "dlogits = dnorm_logits.clone()  # 1.0 * dnorm_logits\n",
    "dlogit_maxes = (-1.0 * dnorm_logits).sum(1, keepdims=True)  # BATAL\n",
    "\n",
    "tmp = torch.zeros_like(logits)\n",
    "tmp[range(n), logits.argmax(1)] = 1\n",
    "dlogits += tmp * dlogit_maxes  # EXTRA BATAL\n",
    "# A.K.'s way for dlogits (2nd branch): dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8ff855dae0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `logits = h @ W2 + b2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27]), torch.Size([27]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.shape, dlogits.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([64, 27]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape, W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits[32x27] = a[32x27] + b[27]\n",
    "#               = a11 + b1 | a12 + b2 | a13 + b3 | ... | a127 + b27\n",
    "#               = a21 + b1 | a22 + b2 | a23 + b3 | ... | a227 + b27\n",
    "#               ...\n",
    "#               = a321 + b1 | a322 + b2 | a323 + b3 | ... | a3227 + b27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = h @ W2 + b2\n",
    "db2 =  dlogits.sum(0)  # dlogits.shape is [32x27], b2.shape is [27], need to get rid of 32 (0th dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h @ W2 \n",
    "\n",
    "# a11 = b11*c11 + b12*c21 + b13*c31\n",
    "# a12 = b11*c12 + b12*c22 + b13*c32\n",
    "# a21 = b21*c11 + b22*c21 + b23*c31\n",
    "# a22 = b21*c12 + b22*c22 + b23*c32\n",
    "# a31 = b31*c11 + b32*c21 + b33*c31\n",
    "# a32 = b31*c12 + b32*c22 + b33*c33\n",
    "\n",
    "# ==> db11 = da11 * c11 + da12 * c12\n",
    "# ==> db12 = da11 * c21 + da12 * c22\n",
    "# ==> db13 = da11 * c31 + da12 * c32\n",
    "# ==> db21 = da21 * c11 + da22 * c12\n",
    "# ==> db32 = da31 * c21 + da32 * c22\n",
    "\n",
    "# THIS IS THE SAME AS:\n",
    "# db = da @ c.T\n",
    "\n",
    "# Same for c:\n",
    "# dc = b.T @ da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dh = torch.zeros_like(h)\n",
    "# for i in range(dh.shape[0]):\n",
    "#     for j in range(dh.shape[1]):\n",
    "#         dh[i, j] = sum(dlog * w2_el for dlog, w2_el in zip(dlogits[i], W2[j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([64, 27]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits.shape, W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR\n",
    "dh = dlogits @ W2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = h.T @ dlogits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `h = torch.tanh(hpreact)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhpreact = (1.0 - h**2) * dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `hpreact = bngain * bnraw + bnbias`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.shape, bngain.shape, bnraw.shape, bnbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnbias = dhpreact.sum(0, keepdims=True)\n",
    "dbnraw = dhpreact * bngain\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### `bnraw = bndiff * bnvar_inv`\n",
    "##### `bnvar_inv = (bnvar + 1e-5) ** -0.5`\n",
    "##### `bnvar = 1 / (n - 1) * (bndiff2).sum(0, keepdim=True)`\n",
    "##### `bndiff2 = bndiff**2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnraw.shape, bndiff.shape, bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff = dbnraw * bnvar_inv\n",
    "dbnvar_inv = (dbnraw * bndiff).sum(0, keepdims=True)\n",
    "\n",
    "# bnvar_inv = (bnvar + 1e-5) ** -0.5 ==> -0.5 * 1/(bnvar + 1e-5)**1.5\n",
    "dbnvar = dbnvar_inv * -0.5 * (bnvar + 1e-5)**-1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnvar.shape, bndiff2.shape, dbnvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bnvar = 1 / (n - 1) * (bndiff2).sum(0, keepdim=True)\n",
    "# a1 = 1/(n-1) *  b11 + b12 + b13 ...\n",
    "# a2 = 1/(n-1) *  b21 + b22 + b23 ...\n",
    "dbndiff2 =  (1/(n-1)) * dbnvar * torch.ones_like(bndiff2)\n",
    "\n",
    "# bndiff2 = bndiff**2\n",
    "dbndiff += (2 * bndiff) * dbndiff2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `bndiff = hprebn - bnmeani`\n",
    "##### `bnmeani = 1 / n * hprebn.sum(0, keepdim=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff.shape, hprebn.shape, bnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bndiff = hprebn - bnmeani\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0, keepdims=True)\n",
    "\n",
    "# bnmeani = 1 / n * hprebn.sum(0, keepdim=True)\n",
    "dhprebn += torch.ones_like(hprebn) * dbnmeani * 1/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `hprebn = embcat @ W1 + b1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, embcat.shape, W1.shape, b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `embcat = emb.view(emb.shape[0], -1)`\n",
    "##### `emb = C[Xb]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]),\n",
       " torch.Size([32, 3, 10]),\n",
       " torch.Size([27, 10]),\n",
       " torch.Size([32, 3]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embcat.shape, emb.shape, C.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "demb = dembcat.view(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xb = [[1, 3], [2, 1], [5, 2]]\n",
    "# C = [[c11, c12, ...], [c21, c22, ..], [c31, c32, ..], [c41, c42, ..], [c51, 52, ..], [c61, c62, ..]]\n",
    "# emb = C[Xb] = [\n",
    "#     [[c11, c12, ...], [c31, c32, ...]],\n",
    "#     [[c21, c22, ...], [c11, c12, ...]],\n",
    "#     [[c51, c52, ...], [c21, c22, ...]],\n",
    "# ]\n",
    "\n",
    "# In english...\n",
    "# emb [32x3x10] represents 32 examples, 3 characters with  10 dimensional embeddings each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demb.shape, C.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = torch.zeros_like(C)\n",
    "for i in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        dC[Xb[i, j]] += 1.0 * demb[i, j]\n",
    "# MEGA BATAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bngain          | exact: False | approximate: True  | maxdiff: 2.0954757928848267e-09\n",
      "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "bnraw           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "bnvar           | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
      "bndiff2         | exact: False | approximate: True  | maxdiff: 2.1827872842550278e-11\n",
      "bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bnmeani         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "hprebn          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "embcat          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "W1              | exact: False | approximate: True  | maxdiff: 3.958120942115784e-09\n",
      "b1              | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "emb             | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "C               | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "to complete this challenge look at the mathematical expression of the loss,\n",
    "take the derivative, simplify the expression, and just write it out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3660807609558105 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits *= 1/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.984919309616089e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# -----------------\n",
    "# YOUR CODE HERE :)\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits = dlogits / n\n",
    "# -----------------\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "take the derivative w.r.t. its input, simplify the expression, and just write it out <br/>\n",
    "BatchNorm paper: https://arxiv.org/abs/1502.03167\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "# -----------------\n",
    "# YOUR CODE HERE :)\n",
    "# dhprebn = None # TODO. my solution is 1 (long) line\n",
    "dhprebn = (bngain * bnvar_inv) * (\n",
    "    dhpreact\n",
    "    - (1/n)*dhpreact.sum(0)\n",
    "    - (bnraw/(n-1)) * (bnraw * dhpreact).sum(0)\n",
    ")\n",
    "# -----------------\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhpreact.sum(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: putting it all together!\n",
    "Train the MLP neural net with your own backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.8245\n",
      "  10000/ 200000: 2.1715\n",
      "  20000/ 200000: 2.4006\n",
      "  30000/ 200000: 2.4569\n",
      "  40000/ 200000: 1.9962\n",
      "  50000/ 200000: 2.4305\n",
      "  60000/ 200000: 2.3470\n",
      "  70000/ 200000: 2.0743\n",
      "  80000/ 200000: 2.3341\n",
      "  90000/ 200000: 2.1615\n",
      " 100000/ 200000: 1.9239\n",
      " 110000/ 200000: 2.3310\n",
      " 120000/ 200000: 1.9826\n",
      " 130000/ 200000: 2.4293\n",
      " 140000/ 200000: 2.2704\n",
      " 150000/ 200000: 2.0950\n",
      " 160000/ 200000: 1.9071\n",
      " 170000/ 200000: 1.8234\n",
      " 180000/ 200000: 2.0095\n",
      " 190000/ 200000: 1.9261\n"
     ]
    }
   ],
   "source": [
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "    # kick off optimization\n",
    "    for i in range(max_steps):\n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix]  # batch X,Y\n",
    "\n",
    "        # forward pass\n",
    "        emb = C[Xb]  # embed the characters into vectors\n",
    "        embcat = emb.view(emb.shape[0], -1)  # concatenate the vectors\n",
    "        # Linear layer\n",
    "        hprebn = embcat @ W1 + b1  # hidden layer pre-activation\n",
    "        # BatchNorm layer\n",
    "        # -------------------------------------------------------------\n",
    "        bnmean = hprebn.mean(0, keepdim=True)\n",
    "        bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "        bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
    "        bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "        hpreact = bngain * bnraw + bnbias\n",
    "        # -------------------------------------------------------------\n",
    "        # Non-linearity\n",
    "        h = torch.tanh(hpreact)  # hidden layer\n",
    "        logits = h @ W2 + b2  # output layer\n",
    "        loss = F.cross_entropy(logits, Yb)  # loss function\n",
    "\n",
    "        # backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        # loss.backward()  # use this for correctness comparisons, delete it later!\n",
    "\n",
    "        # manual backprop! #swole_doge_meme\n",
    "        # -----------------\n",
    "        # YOUR CODE HERE :)\n",
    "        # dC, dW1, db1, dW2, db2, dbngain, dbnbias = None, None, None, None, None, None, None\n",
    "        # cross entropy\n",
    "        dlogits = F.softmax(logits, 1)\n",
    "        dlogits[range(n), Yb] -= 1\n",
    "        dlogits /= n\n",
    "        # hidden layer\n",
    "        dh = dlogits @ W2.T\n",
    "        dW2 = h.T @ dlogits\n",
    "        db2 = dlogits.sum(0)\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "        # BatchNorm layer\n",
    "        dbngain = (bnraw * dhpreact).sum(0, keepdims=True)\n",
    "        dbnbias = dhpreact.sum(0, keepdims=True)\n",
    "        dhprebn = (bngain * bnvar_inv) * (\n",
    "            dhpreact - (1 / n) * dhpreact.sum(0) - (bnraw / (n - 1)) * (bnraw * dhpreact).sum(0)\n",
    "        )\n",
    "        # Linear layer\n",
    "        dembcat = dhprebn @ W1.T\n",
    "        dW1 = embcat.T @ dhprebn\n",
    "        db1 = dhprebn.sum(0)\n",
    "        demb = dembcat.view(emb.shape)\n",
    "        dC = torch.zeros_like(C)\n",
    "        for k in range(Xb.shape[0]):\n",
    "            for j in range(Xb.shape[1]):\n",
    "                dC[Xb[k, j]] += demb[k, j]\n",
    "        grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "        # -----------------\n",
    "\n",
    "        # update\n",
    "        lr = 0.1 if i < 100000 else 0.01  # step learning rate decay\n",
    "        for p, grad in zip(parameters, grads):\n",
    "            # p.data += -lr * p.grad  # old way of cheems doge (using PyTorch grad from .backward())\n",
    "            p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "        # track stats\n",
    "        if i % 10000 == 0:  # print every once in a while\n",
    "            print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}\")\n",
    "        lossi.append(loss.log10().item())\n",
    "\n",
    "        # if i >= 100:  # TODO: delete early breaking when you're ready to train the full net\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 10)        | exact: False | approximate: True  | maxdiff: 1.862645149230957e-08\n",
      "(30, 200)       | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(200,)          | exact: False | approximate: True  | maxdiff: 5.122274160385132e-09\n",
      "(200, 27)       | exact: False | approximate: True  | maxdiff: 2.2351741790771484e-08\n",
      "(27,)           | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 3.259629011154175e-09\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
     ]
    }
   ],
   "source": [
    "# useful for checking your gradients\n",
    "for p,g in zip(parameters, grads):\n",
    "  cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.071169853210449\n",
      "val 2.110775947570801\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I achieved:\n",
    "# train 2.0718822479248047\n",
    "# val 2.1162495613098145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "mayanniee.\n",
      "mad.\n",
      "rylle.\n",
      "emmadiendraeg.\n",
      "adelynnelin.\n",
      "shi.\n",
      "jen.\n",
      "eden.\n",
      "estanaraelyn.\n",
      "malara.\n",
      "noshubergihamie.\n",
      "trick.\n",
      "welle.\n",
      "jose.\n",
      "casubekahdi.\n",
      "jamyleyeks.\n",
      "kaysh.\n",
      "samyah.\n",
      "hal.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
